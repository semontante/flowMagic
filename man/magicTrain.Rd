% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/training.R
\name{magicTrain}
\alias{magicTrain}
\title{magicTrain}
\usage{
magicTrain(df_train, n_cores = 1, train_model = "rf", k_cv = 10,
  list_index_train = NULL, list_index_val = NULL, n_tree = 10,
  tune_lenght = 3, size_nnet_units = 100, decay_nnet = 0.1,
  method_control = "oob", type_y = "classes", seed_n = 40)
}
\arguments{
\item{df_train}{training dataframe generated by the get_train_data function.}

\item{n_cores}{Number of cores to use. Default to 1.}

\item{train_model}{Type of training model. Default to rf.}

\item{k_cv}{Number of k for cross-validation (if method control=cv)}

\item{list_index_train}{List of vector of indices to use in training for each fold.}

\item{list_index_val}{List of vector of indices to use as held out data for each fold.}

\item{n_tree}{Number of trees for random forest.}

\item{tune_lenght}{Number of parameters values trained during cross-validation.}

\item{size_nnet_units}{Number of units in hidden layer (if train_model=nnet).}

\item{decay_nnet}{Decay parameter value for nnet model.}

\item{method_control}{Type of training control: oob or cv. Default to oob.}

\item{type_y}{Type of response variable: classes (train to predict gates boundaries) or n_gates_info(train to predict number of gates).}

\item{seed_n}{Set seed. Default to 40.}
}
\value{
model object.
}
\description{
function to generate one training model based on a list of training sets (no hierarchy).
}
\examples{
\donttest{magicTrain()}
}
